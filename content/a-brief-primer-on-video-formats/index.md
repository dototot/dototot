---
title: A Brief Primer on Video Formats
image: vidformats.jpg
description: Video formats are terribly important for video editors to understand. They are also incredibly boring. So I’ll be as brief as I can while hitting the major points you should familiarize yourself with. Lets start with a dash of history.
---

Video formats are terribly important for video editors to understand. They are also incredibly boring. So I’ll be as brief as I can while hitting the major points you should familiarize yourself with. Lets start with a dash of history. NTSC was the analog standard for broadcast television in most of North and South America. Other popular formats from around the world that you may encounter include PAL and SECAM. Now that digital broadcasting is all the rage, it’s not terribly important for you to understand these. You will, however, undoubtedly see it mentioned in various editing programs. NTSC makes an appearance in the Lightworks project settings, and is referring to the frame size. The width of an NTSC video is 720 pixels, and the height is 480 pixels. 16:9 and 4:3 are the pixel aspect ratio and translate to “widescreen” and “full screen” respectively. But this is the two thousands, so you’re probably all about high definition video, no?

I’m sure you’ve heard the terms 720p and 1080p before. These are shorthand for two popular, high-definition video formats. 720p means the video is 1,280 pixels wide and 720 pixels tall. 1080p means the video is 1,920 pixels wide and 1,080 pixels tall. The “p” means progressive. Progressive video is drawn on your screen one row of pixels at a time to achieve the sharpest result. This is in contrast to the old, analog way of displaying video called interlacing. Interlaced video combines two video fields by first drawing every odd row of pixels, then alternately drawing the even rows.

![Example of interlaced video](./interlacing.jpg)

Interlaced videos can only be played back natively on analog screens. When viewed on digital screens, the video source must first be deinterlaced. You can easily spot an interlaced video because the image will have comb-like artifacts around any moving objects. HD videos occasionally come in the interlaced flavor, but these are less common than progressive.

I’m skimming over this material rather quickly, so if you’re looking to cure your insomnia, you are welcome to check out these comprehensive articles about [video](https://en.wikipedia.org/wiki/Video_formats), [progressive scan](https://en.wikipedia.org/wiki/Progressive_scan), and [interlacing](https://en.wikipedia.org/wiki/Interlaced_video).

The last, and perhaps most important thing I want to cover is video frame rates. The frame rate of a video is the frequency at which unique, consecutive images are produced, creating the illusion of motion. A video can have any frame rate you want, but there are some standard formats you should stick to. Traditionally, broadcast television is set at 30 frames per second (fps). Well, that’s not entirely true. Because of old NTSC standards, 30 fps video often actually translates to 29.97 fps. Unless your name is Peter Jackson, film is 24 fps. This is because 24 fps is the lowest frame rate that still produces fluid motion. In Europe, film is historically 25 fps. These frame rates are still used today in digital videos to achieve a film-like appearance. Be aware that another NTSC carry-over will often see 24 fps video at 23.976 fps. For a more in depth look at video frame rates, check out [this article](https://en.wikipedia.org/wiki/Frame_rate). Otherwise, [start editing your own videos](https://dototot.com/setting-up-your-first-lightworks-project/ "Setting Up Your First Lightworks Project") already!
